{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os,natsort\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tnrange, tqdm\n",
    "from modelTraining.modelDefinition import get_instance_segmentation_model\n",
    "from DatasetUtils.FimgHandling import normalizeImg,cutTrayInIndividualImages, prepareForModel\n",
    "from DatasetUtils.ConvenientFunctions import get_average_and_store, create_time_series\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "sns.reset_defaults()\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu3): ReLU(inplace=True)\n",
       "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu4): ReLU(inplace=True)\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model =get_instance_segmentation_model(2)\n",
    "stateDict = torch.load(\"Models/Leaf_Segmentation_MaskedRCNN_7_7_2022_8h.h5\",map_location=device)\n",
    "model.load_state_dict(stateDict)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Images ordering\n",
    "As the dataset requires a previous work on ordering due to export labeling issues, here we provide the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbae3d67fb954bdc8fafca266c2acfbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61e3c7287884e77be8a96ebadcbdd85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder_path1 = \"Datasets/Tracking_validation_dataset/ParametersImages_8_DAS_17\"\n",
    "folder_path2 = \"Datasets/Tracking_validation_dataset/ParametersImages_18_DAS_26\"\n",
    "folder_path3 = \"Datasets/Tracking_validation_dataset/ParametersImages\"\n",
    "tray_ID = \"002\"\n",
    "files1 = os.listdir(folder_path1)\n",
    "files1 = [e for e in files1 if e.endswith(\"Fmp.fimg\")]\n",
    "files1 = natsort.natsorted([folder_path1+\"/\"+e for e in files1 if tray_ID in e])\n",
    "files2 = os.listdir(folder_path2)\n",
    "files2 = [e for e in files2 if e.endswith(\"Fmp.fimg\")]\n",
    "files2 = natsort.natsorted([folder_path2+\"/\"+e for e in files2 if tray_ID in e])\n",
    "files12 =files1 + files2\n",
    "files3 = os.listdir(folder_path3)\n",
    "files3 = [e for e in files3 if (e.endswith(\"Fm.fimg\") and not (e.endswith(\"Fv_Fm.fimg\")))]\n",
    "files3 = natsort.natsorted([folder_path3+\"/\"+e for e in files3 if tray_ID in e])\n",
    "files = []\n",
    "for i in range(len(files3)):\n",
    "    files += [files3[0]]\n",
    "    files +=files12[0:2]\n",
    "    files3.pop(0)\n",
    "    files12.pop(0)\n",
    "    files12.pop(0)\n",
    "tray = []\n",
    "normalized_tray = []\n",
    "for i in tnrange(len(files)):\n",
    "    fimg_path = files[i]\n",
    "    this_tray = cutTrayInIndividualImages(fimg_path,normalized=False)\n",
    "    images = []\n",
    "    for e in this_tray:\n",
    "        img = e.copy()\n",
    "        img[img < 0]= 0\n",
    "        images.append(img)\n",
    "    tray.append(images)\n",
    "    this_normalized_tray = [normalizeImg(e,torch_format=True) for e in images]\n",
    "    this_normalized_tray = prepareForModel(this_normalized_tray)\n",
    "    normalized_tray.append(this_normalized_tray)\n",
    "folder_path1 = \"Datasets/Tracking_validation_dataset/ParametersImages_8_DAS_17\"\n",
    "folder_path2 = \"Datasets/Tracking_validation_dataset/ParametersImages_18_DAS_26\"\n",
    "folder_path3 = \"Datasets/Tracking_validation_dataset/ParametersImages\"\n",
    "files1 = os.listdir(folder_path1)\n",
    "files1 = [e for e in files1 if e.endswith(\"Fp.fimg\")]\n",
    "files1 = natsort.natsorted([folder_path1+\"/\"+e for e in files1 if tray_ID in e])\n",
    "files2 = os.listdir(folder_path2)\n",
    "files2 = [e for e in files2 if e.endswith(\"Fp.fimg\")]\n",
    "files2 = natsort.natsorted([folder_path2+\"/\"+e for e in files2 if tray_ID in e])\n",
    "files12 =files1 + files2\n",
    "files3 = os.listdir(folder_path3)\n",
    "files3 = [e for e in files3 if (e.endswith(\"Fo.fimg\") and not (e.endswith(\"Fv_Fm.fimg\")))]\n",
    "files3 = natsort.natsorted([folder_path3+\"/\"+e for e in files3 if tray_ID in e])\n",
    "files = []\n",
    "for i in range(len(files3)):\n",
    "    files += [files3[0]]\n",
    "    files +=files12[0:2]\n",
    "    files3.pop(0)\n",
    "    files12.pop(0)\n",
    "    files12.pop(0)\n",
    "\n",
    "tray_fo = []\n",
    "for i in tnrange(len(files)):\n",
    "    fimg_path = files[i]\n",
    "    this_tray_fo = cutTrayInIndividualImages(fimg_path, normalized=False)\n",
    "    images = []\n",
    "    for e in this_tray_fo:\n",
    "        img = e.copy()\n",
    "        img[img < 0] = 0\n",
    "        images.append(img)\n",
    "    tray_fo.append(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model usage\n",
    "Eventhough this cell is does not require GPU to run, it is highly encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dc9dcbe29d4f18b60e4d3664c5341f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if device.type == \"cuda\":\n",
    "    results = []\n",
    "    for i in tqdm(normalized_tray):\n",
    "        i = i.cuda()\n",
    "        this_result = model(i)\n",
    "        for idx,result in enumerate(this_result):\n",
    "            for k,v in result.items():\n",
    "                result[k] = v.detach().cpu()\n",
    "            this_result[idx] = result\n",
    "        results.append(this_result)\n",
    "        del result\n",
    "        del v\n",
    "        del this_result\n",
    "        del i\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    results = []\n",
    "    for i in tqdm(normalized_tray):\n",
    "        this_result=model(i)\n",
    "        for idx,result in enumerate(this_result):\n",
    "            for k,v in result.items():\n",
    "                result[k] = v.detach()\n",
    "            this_result[idx] = result\n",
    "        results.append(this_result)\n",
    "        del this_result\n",
    "        del i\n",
    "        del v\n",
    "        del result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Running the association process and information store\n",
    "\n",
    "In the following cell we perform the tracking as described in the manuscript. We also perform the PSII, Fmp, and Fp analysis and estimation, all wrapped in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cf5b61f3f7437188dc757bfd7cfa63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '002_A1/A1\\\\A1_phiPSII_graph.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fjurado\\Desktop\\Leaf Tracking\\Leaf-Tracking\\Example_run.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fjurado/Desktop/Leaf%20Tracking/Leaf-Tracking/Example_run.ipynb#X10sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m plt\u001b[39m.\u001b[39mxticks(total_average\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mtolist())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fjurado/Desktop/Leaf%20Tracking/Leaf-Tracking/Example_run.ipynb#X10sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m plt\u001b[39m.\u001b[39mlegend()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fjurado/Desktop/Leaf%20Tracking/Leaf-Tracking/Example_run.ipynb#X10sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m plt\u001b[39m.\u001b[39;49msavefig(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39m\"\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(tray_number,name,name)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fjurado/Desktop/Leaf%20Tracking/Leaf-Tracking/Example_run.ipynb#X10sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m                          ,\u001b[39m\"\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_phiPSII_graph.png\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(name)),dpi\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\fjurado\\.conda\\envs\\torchGPU\\lib\\site-packages\\matplotlib\\pyplot.py:958\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[39m.\u001b[39msavefig)\n\u001b[0;32m    956\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msavefig\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    957\u001b[0m     fig \u001b[39m=\u001b[39m gcf()\n\u001b[1;32m--> 958\u001b[0m     res \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39msavefig(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    959\u001b[0m     fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mdraw_idle()   \u001b[39m# need this if 'transparent=True' to reset colors\u001b[39;00m\n\u001b[0;32m    960\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\fjurado\\.conda\\envs\\torchGPU\\lib\\site-packages\\matplotlib\\figure.py:3019\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3015\u001b[0m     \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes:\n\u001b[0;32m   3016\u001b[0m         stack\u001b[39m.\u001b[39menter_context(\n\u001b[0;32m   3017\u001b[0m             ax\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39m_cm_set(facecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m, edgecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m-> 3019\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mprint_figure(fname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fjurado\\.conda\\envs\\torchGPU\\lib\\site-packages\\matplotlib\\backend_bases.py:2319\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2316\u001b[0m     \u001b[39m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2317\u001b[0m     \u001b[39m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2318\u001b[0m     \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, dpi\u001b[39m=\u001b[39mdpi):\n\u001b[1;32m-> 2319\u001b[0m         result \u001b[39m=\u001b[39m print_method(\n\u001b[0;32m   2320\u001b[0m             filename,\n\u001b[0;32m   2321\u001b[0m             facecolor\u001b[39m=\u001b[39mfacecolor,\n\u001b[0;32m   2322\u001b[0m             edgecolor\u001b[39m=\u001b[39medgecolor,\n\u001b[0;32m   2323\u001b[0m             orientation\u001b[39m=\u001b[39morientation,\n\u001b[0;32m   2324\u001b[0m             bbox_inches_restore\u001b[39m=\u001b[39m_bbox_inches_restore,\n\u001b[0;32m   2325\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2326\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   2327\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32mc:\\Users\\fjurado\\.conda\\envs\\torchGPU\\lib\\site-packages\\matplotlib\\backend_bases.py:1648\u001b[0m, in \u001b[0;36m_check_savefig_extra_args.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1640\u001b[0m     _api\u001b[39m.\u001b[39mwarn_deprecated(\n\u001b[0;32m   1641\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m3.3\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39mname, removal\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m3.6\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1642\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m() got unexpected keyword argument \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1643\u001b[0m                 \u001b[39m+\u001b[39m arg \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m which is no longer supported as of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1644\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m and will become an error \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1645\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1646\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(arg)\n\u001b[1;32m-> 1648\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fjurado\\.conda\\envs\\torchGPU\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:412\u001b[0m, in \u001b[0;36mdelete_parameter.<locals>.wrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m     deprecation_addendum \u001b[39m=\u001b[39m (\n\u001b[0;32m    403\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIf any parameter follows \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m!r}\u001b[39;00m\u001b[39m, they should be passed as \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    404\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mkeyword, not positionally.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    405\u001b[0m     warn_deprecated(\n\u001b[0;32m    406\u001b[0m         since,\n\u001b[0;32m    407\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39mrepr\u001b[39m(name),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    410\u001b[0m                  \u001b[39melse\u001b[39;00m deprecation_addendum,\n\u001b[0;32m    411\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 412\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39minner_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minner_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\fjurado\\.conda\\envs\\torchGPU\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:541\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[39mWrite the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[39m    *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    540\u001b[0m FigureCanvasAgg\u001b[39m.\u001b[39mdraw(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 541\u001b[0m mpl\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mimsave(\n\u001b[0;32m    542\u001b[0m     filename_or_obj, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuffer_rgba(), \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpng\u001b[39;49m\u001b[39m\"\u001b[39;49m, origin\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mupper\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    543\u001b[0m     dpi\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdpi, metadata\u001b[39m=\u001b[39;49mmetadata, pil_kwargs\u001b[39m=\u001b[39;49mpil_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\fjurado\\.conda\\envs\\torchGPU\\lib\\site-packages\\matplotlib\\image.py:1675\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1673\u001b[0m pil_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mformat\u001b[39m)\n\u001b[0;32m   1674\u001b[0m pil_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mdpi\u001b[39m\u001b[39m\"\u001b[39m, (dpi, dpi))\n\u001b[1;32m-> 1675\u001b[0m image\u001b[39m.\u001b[39msave(fname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpil_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\fjurado\\.conda\\envs\\torchGPU\\lib\\site-packages\\PIL\\Image.py:2209\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2207\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mr+b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2208\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2209\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mw+b\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   2211\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2212\u001b[0m     save_handler(\u001b[39mself\u001b[39m, fp, filename)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '002_A1/A1\\\\A1_phiPSII_graph.png'"
     ]
    }
   ],
   "source": [
    "trays_order =[\"A1\",\"B1\",\"C1\",\"A2\",\"B2\",\"C2\",\"A3\",\"B3\",\"C3\"]\n",
    "tray_number = \"002\"\n",
    "tray_name = \"example_tray\"\n",
    "for i in tnrange(9):\n",
    "\n",
    "    name = trays_order[i]\n",
    "    time_series, series,images = create_time_series(tray,results,index=i)\n",
    "\n",
    "\n",
    "    get_average_and_store(path=\"{}_{}\".format(tray_name,tray_number),\n",
    "                          time_series=time_series,\n",
    "                          series=series,\n",
    "                          images=images,\n",
    "                          name=name,\n",
    "                          line_plot=True,\n",
    "                          gif=True,\n",
    "                          save_masks=True,\n",
    "                          save_fcam_values=True,\n",
    "                          type=\"Fmp\")\n",
    "    images_fo = []\n",
    "    for e in tray_fo:\n",
    "        img = e[i].copy()\n",
    "        img[img < 0]= 0\n",
    "        images_fo.append(img)\n",
    "    get_average_and_store(path=\"{}_{}\".format(tray_name,tray_number),\n",
    "                          time_series=time_series,\n",
    "                          series=series,\n",
    "                          images=images_fo,\n",
    "                          name=name,\n",
    "                          line_plot=True,\n",
    "                          gif=False,\n",
    "                          save_masks=False,\n",
    "                          save_fcam_values=True,\n",
    "                          type=\"Fo\")\n",
    "    df1 = pd.read_csv(\"{}_{}/{}/{}_Fmp_Average_Flcam_values_per_leaf.tsv\".format(tray_name,tray_number,name,name),\n",
    "                      sep=\"\\t\",\n",
    "                      index_col=0)\n",
    "    df2 = pd.read_csv(\"{}_{}/{}/{}_Fo_Average_Flcam_values_per_leaf.tsv\".format(tray_name,tray_number,name,name),\n",
    "                      sep=\"\\t\",\n",
    "                      index_col=0)\n",
    "    val = (df1.values - df2.values)\n",
    "    val[val < 0] = 0\n",
    "    val = val/df1.values\n",
    "    total_average = pd.DataFrame(val)\n",
    "    total_average.to_csv(\"{}_{}/{}/{}_phiPSII_Average_Flcam_values_per_leaf.tsv\".format(tray_name,tray_number,name,name),\n",
    "                             sep=\"\\t\")\n",
    "    plt.figure(figsize=(12,8))\n",
    "    sns.lineplot(data=total_average)\n",
    "    plt.xticks(total_average.index.tolist())\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(\"{}_{}/{}\".format(tray_name,tray_number,name,name)\n",
    "                             ,\"{}_phiPSII_graph.png\".format(name)),dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torchGPU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "118487b1b61bd11bfc0fa122cb4895870a0a05b9d302d1e57edad66962da4c3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
